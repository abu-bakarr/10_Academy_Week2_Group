{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZcBSucptw_tT"
   },
   "source": [
    "### **2.1. Data split**\n",
    "\n",
    "A ratio of 80/20 is used for data splitting such that 80% goes to the training subset and 20% to the testing subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bWItU-xbw_tY"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (138150450.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_61679/138150450.py\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    ----------------------------------------------------------------------\u001b[0m\n\u001b[0m                                                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(svc,'project21-carcomforttype.obj')\n",
    "----------------------------------------------------------------------\n",
    "model=joblib.load('/home/ermi/Desktop/10Academy/week2/Ad-campaign-performance-/models/clf_lrm.joblib')\n",
    "----------------------------------------------------------------------\n",
    "Final_predictions=model.predict(x_test)\n",
    "Final_predictions=pd.DataFrame(Final_predictions,columns=['unacc(0),acc(1),good(2),vgood(3)'])\n",
    "Final_predictions[:5]\n",
    "----------------------------------------------------------------------\n",
    "Final_predictions.sample(n=10)\n",
    "--------------------------------------------------------------------\n",
    "#Saving final predictions in file.csv format\n",
    "Final_predictions.to_csv('final_predictionscarcomforttype',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-58VLXQsw_tq"
   },
   "source": [
    "### **2.2. Let's examine the data dimension**\n",
    "\n",
    "Here we see that the **training set** has 160 rows and 10 columns while there are 160 rows and 1 column for the **Y** variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "D7UxtTrJw_tw",
    "outputId": "56fa6fa1-7d77-433a-c3f5-402bd013b329"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((160, 10), (160,))"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x6l7J5PqBFnp"
   },
   "source": [
    "The **testing set** has 40 rows and 10 columns for the **X** variable while there are 40 rows and 1 column for the **Y** variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Jvt4See2w_uE",
    "outputId": "9b87742a-0408-484b-e0dc-75c9573a7292"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40, 10), (40,))"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IuzvrUrCDZyr"
   },
   "source": [
    "# **3. Building a simple machine learning model using Random Forest**\n",
    "\n",
    "In the following blocks of codes, we will first start with building a random forest model. Finally, we will explore how to tune the hyperparameters (e.g. **n_estimators** and **max_features**) of the random forest algorithm. \n",
    "\n",
    "We first start by importing the necessary libraries and assigning the random forest classifier to the **rf** variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5JzOz1gU1OSu"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rf = RandomForestClassifier(max_features=5, n_estimators=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-5b-q8kVGsRL"
   },
   "source": [
    "Now, we will be applying the random forest classifier to build a classification model using the **rf.fit()** function on the training data (e.g. **X_train** and **Y_train**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "J5207y6A1Vax",
    "outputId": "106f8a36-5243-4483-e514-562be5e048f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features=5,\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3ppx4mdtHzDy"
   },
   "source": [
    "The **rf.score()** function will be used to calculate the accuracy score of the RF model in predicting the *test data* (**X_test**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RZ7vmyEJ1iNV",
    "outputId": "cf493dc7-d7e4-4872-d670-4894d23659fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.875"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6281UxefI1Jm"
   },
   "source": [
    "The following 2 code cells also calculate the accuracy score of the RF model in predicting the test data (X_test) but performs it in 2 steps using **rf.predict()** and **accuracy_score()** functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G19rlbJ41nd1"
   },
   "outputs": [],
   "source": [
    "Y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UCCS1JORaut5",
    "outputId": "e99e80dc-85b2-407e-8c4f-4ac05d840281"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.875"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_pred, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J6r_AY5bKfZu"
   },
   "source": [
    "The advantage of using this latter approach is that you have access to the predicted data values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "E4XPCkdxJccQ",
    "outputId": "a14a38b3-2dbb-4096-cdc1-fbe6acae4a83"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "        0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1]))"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yfdK3TpVUH0t"
   },
   "source": [
    "# **4. Hyperparameter Tuning**\n",
    "\n",
    "Now we will be performing the tuning of hyperparameters of Random forest model. The hyperparameters that we will tune includes **max_features** and the **n_estimators**.\n",
    "\n",
    "Note: Some codes modified from [scikit-learn](http://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html)\n",
    "\n",
    "Firstly, we will import the necessary modules.\n",
    "\n",
    "The **GridSearchCV()** function from scikit-learn will be used to perform the hyperparameter tuning. Particularly, **GridSearchCV()** function can perform the typical functions of a classifier such as ***fit***, ***score*** and ***predict*** as well as ***predict_proba***, ***decision_function***, ***transform*** and ***inverse_transform***.\n",
    "\n",
    "Secondly, we define variables that are necessary input to the GridSearchCV() function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lMI5UTrUUgwR"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "max_features_range = np.arange(1,6,1)\n",
    "n_estimators_range = np.arange(10,210,10)\n",
    "param_grid = dict(max_features=max_features_range, n_estimators=n_estimators_range)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "grid = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "hyperparameter-tuning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
